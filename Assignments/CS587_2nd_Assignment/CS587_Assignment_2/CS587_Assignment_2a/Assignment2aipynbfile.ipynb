{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pla0wlS8jZlg"
   },
   "source": [
    "### **Welcome to the 2nd (short) assignment of CS-587!**\n",
    "\n",
    "The aim of this assignment is to get familiar with (a) the Tensorflow framework, and, (b) computational graphs and the information flow (forward, backward operation)!\n",
    "\n",
    "Before this assignment:\n",
    "- Read the 2nd tutorial slides found in [here](https://docs.google.com/presentation/d/1fAoPGhpYGk6hJibHCCXz5VmruLcTOtztU9wP2VZ1DNI/edit?usp=sharing)\n",
    "\n",
    "What you need to submit:\n",
    "\n",
    "a) This .ipynb or .py file\n",
    "\n",
    "b) A report (.pdf) with the requested tasks.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hpbxp4Ftz-Iu"
   },
   "source": [
    "**Quick check on what you have installed** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "r8KYi-Uw0H50",
    "outputId": "910c7d2e-6d52-4fb8-a21c-6f5757c946f3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python version: 3.5.6 |Anaconda, Inc.| (default, Aug 26 2018, 21:41:56) \n",
      "[GCC 7.3.0]\n",
      "TensorFlow version: 1.15.0\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(\"Python version:\", sys.version)\n",
    "\n",
    "import tensorflow as tf\n",
    "print(\"TensorFlow version:\", tf.__version__) #1.15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aeIJ16AUQusx"
   },
   "source": [
    "# **Part - 1: Basic TF operations**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-FJ24zCm88jU"
   },
   "source": [
    "## Examples:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ac4lAe9Ai5M8"
   },
   "source": [
    "Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "id": "gEhLZ0xPiGLR",
    "outputId": "7a32bebf-5733-4d62-a291-6783d1c60d6f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a: 2 b: 3\n",
      "Addition with constants: 5\n",
      "Multiplication with constants: 6\n"
     ]
    }
   ],
   "source": [
    "# Basic constant operations\n",
    "# The value returned by the constructor represents the output\n",
    "# of the Constant op.\n",
    "a = tf.constant(2)\n",
    "b = tf.constant(3)\n",
    "\n",
    "# Launch the default graph.\n",
    "with tf.Session() as sess:\n",
    "    print(\"a: %i\" % sess.run(a), \"b: %i\" % sess.run(b))\n",
    "    print (\"Addition with constants: %i\" % sess.run(a+b))\n",
    "    print (\"Multiplication with constants: %i\" % sess.run(a*b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FyZPZMXci9EN"
   },
   "source": [
    "Placeholders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "id": "fRtR-qMa4Q8H",
    "outputId": "adce1697-0bd2-4c29-e6bf-7f02b9fdd7ba"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 4. 9.]\n",
      "[ 0.  0. 25.]\n"
     ]
    }
   ],
   "source": [
    "## Example 1: simple placeholder \"feeding\"\n",
    "\n",
    "# Define a placeholder that expects a vector of three floating-point values,\n",
    "# and a computation that depends on it.\n",
    "x = tf.placeholder(tf.float32, shape=[3])\n",
    "y = tf.square(x)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "  # Feeding a value changes the result that is returned when you evaluate `y`.\n",
    "  print(sess.run(y, {x: [1.0, 2.0, 3.0]}))  # => \"[1.0, 4.0, 9.0]\"\n",
    "  print(sess.run(y, {x: [0.0, 0.0, 5.0]}))  # => \"[0.0, 0.0,25.0]\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "id": "d4HGF-BjjAZk",
    "outputId": "3e5b2e8d-27c2-453b-dce1-7672429ab54f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Addition with variables: 5\n",
      "Multiplication with variables: 12\n",
      "Substract with variables: -1\n"
     ]
    }
   ],
   "source": [
    "## Example 2:  Basic operations with placeholders\n",
    "\n",
    "a = tf.placeholder(tf.int16)\n",
    "b = tf.placeholder(tf.int16)\n",
    "\n",
    "# Define some operations\n",
    "add = tf.add(a, b)\n",
    "mul = tf.multiply(a, b)\n",
    "sub = tf.subtract(a,b)\n",
    "\n",
    "# Launch the default graph.\n",
    "with tf.Session() as sess:\n",
    "    # Run every operation with variable input\n",
    "    print (\"Addition with variables: %i\" % sess.run(add, feed_dict={a: 2, b: 3}))\n",
    "    print (\"Multiplication with variables: %i\" % sess.run(mul, feed_dict={a: 4, b: 3}))\n",
    "    print (\"Substract with variables: %i\" % sess.run(sub, feed_dict={a: 2, b: 3}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YKlZ4Ws69AXh"
   },
   "source": [
    "## **Assignment:**\n",
    "\n",
    "The goal is to define a linear regression model using TF operations, variables and placeholders. \n",
    "\n",
    "\n",
    "**Tasks**:\n",
    "- Define the weights and biases as variables with float32 format. Initialize the weight with 0.3 and the bias with -0.3\n",
    "- Define the x, y as placeholders with float32 format\n",
    "Q.1: Why do we use this formulation?\n",
    "- Define the model operation y = w*x+b\n",
    "\n",
    "- Define the loss (quadratic loss between model output and expected value). \n",
    "- Map some input-output data to your model tf.placeholders (x,y) so that we can evaluate the model.\n",
    "\n",
    "For this assignment you are allowed to use the functions:\n",
    "tf.mul, tf.add, tf.square and tf.reduce_sum \n",
    "\n",
    "As well as any other function in the tf framework that suits your needs.\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "RKWWcPI498Tt"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.5291639, -0.3842745]\n"
     ]
    }
   ],
   "source": [
    "####################################################\n",
    "# TASK: Define the variables weights W and biases b\n",
    "###################################################\n",
    "#W = pass\n",
    "#b = pass\n",
    "W =  tf.Variable(0.3, dtype=tf.float32)\n",
    "b =  tf.Variable(-0.3, dtype=tf.float32)\n",
    "\n",
    "####################################################\n",
    "# TASK: Define inputs and outputs\n",
    "###################################################\n",
    "#x = pass\n",
    "#y = pass\n",
    "x = tf.placeholder(tf.float32)\n",
    "y = tf.placeholder(tf.float32)\n",
    "\n",
    "####################################################\n",
    "# TASK: Define the model\n",
    "####################################################\n",
    "#Model = pass\n",
    "Model = tf.add(tf.multiply(W,x),b)\n",
    "\n",
    "####################################################\n",
    "# TASK: Define the loss: Quadratic loss in our case\n",
    "####################################################\n",
    "#loss = pass\n",
    "loss = tf.reduce_sum(tf.square(Model - y))                   \n",
    "\n",
    "#Define an array to store the loss\n",
    "loss_arr = []\n",
    "\n",
    "#Start an optimizer to minimize loss and estimate the values of W and b that best approximate \n",
    "# the ground-truth output\n",
    "\n",
    "optimizer = tf.train.GradientDescentOptimizer(0.01)\n",
    "train = optimizer.minimize(loss)\n",
    "\n",
    "#Initialize variables\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "# Start a session and actually do the initialization\n",
    "sess = tf.Session()\n",
    "\n",
    "sess.run(init)\n",
    "\n",
    "#And now lets run our model - for 10 iterations\n",
    "for i in range(10):\n",
    "    \n",
    "    ###############################################################################\n",
    "    # TASK:\n",
    "    # -add inside the brackets the values for x, y for which we need to evaluate our model\n",
    "    #   values  x = 1, 2, 3, 4, y = 0, -1, -2, -3\n",
    "    ##############################################################################\n",
    "    #_, lossy = sess.run([train, loss], { })\n",
    "    _, lossy = sess.run([train, loss], {x: [1, 2, 3, 4], y: [0, -1, -2, -3]})\n",
    "    \n",
    "    loss_arr.append(lossy) # store the loss values\n",
    "  \n",
    "# And now let's evaluate the variables (W,b)\n",
    "print(sess.run([W,b]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "lZvAJuJiqGR7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function matplotlib.pyplot.show>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# And now let's see how the loss behaves\n",
    "import matplotlib.pyplot  as plt\n",
    "\n",
    "plt.plot(loss_arr)\n",
    "plt.axis([0, 6, 0, 20])\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IHAAfnFB3Ls4"
   },
   "source": [
    "# **Part - 2: Computational graphs and custom gradients**\n",
    "\n",
    "> Read before doing this part:\n",
    "\n",
    "[tf.custom_gradient](https://www.tensorflow.org/api_docs/python/tf/custom_gradient)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8XgoCal90GQN"
   },
   "source": [
    "## Example: Defining a custom gradient \n",
    "- Specify the forward and backward operations for f(x) = log(1+e^x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2d4NcunQ0Ge1",
    "outputId": "70d48875-bb67-4375-bb49-1135193c0918"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The value of f(x) is: 10.0000458\n",
      "The gradient df/dx is:  0.999954581\n"
     ]
    }
   ],
   "source": [
    "# Define our input\n",
    "x = tf.constant(10.)\n",
    "\n",
    "# Notify tf that we will be defining the forward and backward operations\n",
    "@tf.custom_gradient # The @ is called a decorator, it is similar as writing tf.custom_gradient(log1pexp) \n",
    "def log1pexp(x):\n",
    "  # Forward operation\n",
    "  e = tf.exp(x)\n",
    "  f_x = tf.math.log(1 + e)\n",
    "  \n",
    "  # Backward operation\n",
    "  def grad(upstream): \n",
    "    return upstream * (1 - 1 / (1 + e))\n",
    "  return f_x, grad\n",
    "\n",
    "# Let TF know that we are tracking the specific operation forward and backward \n",
    "with tf.GradientTape(persistent=True) as tape: # it is like a keyword assignment for this process. Alternatively we could just have written\n",
    "# it as tf.GradientTanpe.watch(x)\n",
    "  tape.watch(x)\n",
    "  # Call forward-backward function here to define the operations for y\n",
    "  f_x = log1pexp(x)\n",
    "\n",
    "# Call the operation  \n",
    "Gradient = tape.gradient(f_x, x)\n",
    "\n",
    "# Session: An object that encapsulates the environment in which Operation objects are executed, and Tensor objects are evaluated\n",
    "sess = tf.Session()\n",
    "with sess.as_default():\n",
    "\n",
    "  # Add print operation\n",
    "  sess.run(tf.print(\"The value of f(x) is:\", f_x))\n",
    "  # Add print operation\n",
    "  sess.run(tf.print(\"The gradient df/dx is: \", Gradient))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mXDMaesfykPo"
   },
   "source": [
    "- Define the forward pass of function $f(x) = x^2+1$, and the 1st, 2nd order derivatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mG4ig8wfyeUP",
    "outputId": "3284f538-a07a-41f4-d85b-cd95b7b1e353"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The value of f(x) is: 101\n",
      "The gradient df/dx is:  20\n"
     ]
    }
   ],
   "source": [
    "x = tf.constant(10.)\n",
    "\n",
    "@tf.custom_gradient\n",
    "def op(x):\n",
    "  y = x*x+1\n",
    "  @tf.custom_gradient\n",
    "  def grad_fn(dy):\n",
    "    gdy = 2*x\n",
    "    def grad_grad_fn(ddy):  # Not the 2nd order gradient of op w.r.t. x.\n",
    "      return 2\n",
    "    return gdy, grad_grad_fn\n",
    "  return y, grad_fn\n",
    "\n",
    "  # Let TF know that we are tracking the specific operation forward and backward \n",
    "with tf.GradientTape(persistent=True) as tape:\n",
    "  tape.watch(x)\n",
    "  # Call forward-backward function here to define the operations for y\n",
    "  f_x = op(x)\n",
    "\n",
    "# Call the operation  \n",
    "Gradient = tape.gradient(f_x, x)\n",
    "\n",
    "# Session: An object that encapsulates the environment in which Operation objects are executed, and Tensor objects are evaluated\n",
    "sess = tf.Session()\n",
    "with sess.as_default():\n",
    "\n",
    "  # Add print operation\n",
    "  sess.run(tf.print(\"The value of f(x) is:\", f_x))\n",
    "  # Add print operation\n",
    "  sess.run(tf.print(\"The gradient df/dx is: \", Gradient))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X8M9E_gf3e3r"
   },
   "source": [
    "## **Assignment:**\n",
    "\n",
    "Part 2a.A:\n",
    "  - **Question**: What is the functionality of upstream? Answer it in your report.\n",
    "\n",
    "Part 2a.B: \n",
    "  - Implement the following functions and the requested tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yqUso61lBwE_"
   },
   "source": [
    " **One-variable function:**\n",
    "\n",
    "$y(x) = \\frac{\\sin x}{x}$, derivative is $\\frac{dy}{dx}=$ ????\n",
    "\n",
    "1. Design the computational graph (in your report)\n",
    "2. Compute the derivative for the back propagation process by hand (include the computations in your report)\n",
    "3.  Compute the forward operation and the corresponding backward operation\n",
    "using tf.custom_gradient()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7HZ6Qg_fC5zh",
    "outputId": "8fe5b9c6-5c20-4cb3-cf25-b4284b92077b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The gradient df/dx is:  -0.0784669369\n",
      "The value of y is:  -0.054402113\n"
     ]
    }
   ],
   "source": [
    "############################\n",
    "# TODO: \n",
    "# - define forward pass\n",
    "# - define gradient \n",
    "###############################\n",
    "import sys\n",
    "@tf.custom_gradient\n",
    "def sinx_underx(x):\n",
    "    ################################\n",
    "    # CODE START f(x)              #\n",
    "    ################################\n",
    "    \n",
    "    #func_fx = pass\n",
    "    func_fx = tf.sin(x)/x\n",
    "    \n",
    "    ################################\n",
    "    # CODE END                     #\n",
    "    ################################\n",
    "    def grad(upstream):\n",
    "        ################################\n",
    "        # CODE START f'(x)              #\n",
    "        ################################\n",
    "        \n",
    "        #grad_result = pass\n",
    "        grad_result = upstream *((x * tf.cos(x) - tf.sin(x) )/ (x*x))\n",
    "        \n",
    "        ################################\n",
    "        # CODE END                     #\n",
    "        ################################\n",
    "        return upstream * (grad_result)\n",
    "    return func_fx, grad\n",
    "\n",
    "# Evaluate it with x = 10\n",
    "x = tf.constant(10.)\n",
    "\n",
    "# Let TF know that we are tracking the specific operation forward and backward \n",
    "with tf.GradientTape(persistent=True) as tape:\n",
    "  tape.watch(x)\n",
    "  # Call forward-backward function here to define the operations for y\n",
    "  y = sinx_underx(x)\n",
    "\n",
    "# Call the operation  \n",
    "Gradient = tape.gradient(y, x)\n",
    "\n",
    "# Session: An object that encapsulates the environment in which Operation objects are executed, and Tensor objects are evaluated\n",
    "sess = tf.Session()\n",
    "with sess.as_default():\n",
    "    \n",
    "    ################################\n",
    "    # CODE START                  #\n",
    "    ################################\n",
    " \n",
    "    #############################################################\n",
    "    # TODO: print the value of dy/dx, expected dy/dx = -0.07846694\n",
    "    ############################################################## \n",
    "    #pass\n",
    "    sess.run(tf.print(\"The gradient df/dx is: \", Gradient))\n",
    "    #########################################################\n",
    "    # TODO: print the value of y, expected is y = -0.054402113\n",
    "    ########################################################\n",
    "    #pass\n",
    "    sess.run(tf.print(\"The value of y is: \", y))\n",
    "    ################################\n",
    "    # CODE END                     #\n",
    "    ################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zmL_J3R2AnPU"
   },
   "source": [
    "**Two-variable function**:\n",
    "\n",
    "$$f(x,y) = a x^2 +b xy + c y^2$$\n",
    "\n",
    "1. Design the computational graph by hand (include it in your report, also include the partial derivatives df/dx, df/dy)\n",
    "2. Compute the forward operation and the corresponding backward operation\n",
    "using tf.custom_gradient()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8QWCz9gx9kve",
    "outputId": "3fb314f7-35a9-43dc-eac3-2ff9e174d95a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The gradient df/dx is:  16\n",
      "The gradient df/dy is:  26\n"
     ]
    }
   ],
   "source": [
    "@tf.custom_gradient\n",
    "def bar(x, y):\n",
    "  a = 1.0\n",
    "  b= 4.0 \n",
    "  c = 3.0\n",
    "\n",
    "  ################################\n",
    "  # CODE START f(x,y)            #\n",
    "  ################################\n",
    "  #f = pass\n",
    "  f = a * x * x + b * x * y + c * y * y\n",
    "\n",
    "  ################################\n",
    "  # CODE END                     #\n",
    "  ################################\n",
    "  \n",
    "  def grad(upstream):\n",
    "    ################################\n",
    "    # CODE START df/dx, df/dy      #\n",
    "    ################################\n",
    "    \n",
    "    #df_dx = pass\n",
    "    #df_dy = pass\n",
    "    df_dx = 2 * a * x + b * y\n",
    "    df_dy = x * b + 2 * y * c\n",
    "    \n",
    "    ################################\n",
    "    # CODE END                     #\n",
    "    ################################\n",
    "    return upstream * df_dx, upstream * df_dy\n",
    " \n",
    "  return f, grad\n",
    "\n",
    "# Evaluate on values:  \n",
    "x = tf.constant(2.0, dtype=tf.float32)\n",
    "y = tf.constant(3.0, dtype=tf.float32)\n",
    "with tf.GradientTape(persistent=True) as tape:\n",
    "  tape.watch(x)\n",
    "  tape.watch(y)\n",
    "  f = bar(x, y)\n",
    "\n",
    "# Get the gradient - expected is 16\n",
    "Gradient_x = tape.gradient(f, x)\n",
    "# Add print operation\n",
    "sess.run(tf.print(\"The gradient df/dx is: \", Gradient_x))\n",
    "\n",
    "# Get the gradient y - expected is 14\n",
    "Gradient_y = tape.gradient(f, y)\n",
    "\n",
    "# Add print operation\n",
    "sess.run(tf.print(\"The gradient df/dy is: \", Gradient_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7Hkm_UlU4rX-"
   },
   "source": [
    "**Second-order derivative**:\n",
    "\n",
    "For the function $f(x) = \\log(1+e^{x})$\n",
    "0. Design the computational graph (include it in your report).\n",
    "1. Define the forward pass\n",
    "2. Define the operations that compute the 1st derivative f'(x)\n",
    "3. Define the operations that compute the 2nd derivative f''(x)\n",
    "\n",
    "Evaluate for x = 10, and print the results!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "A6Fp4JBu5QnR"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dy/dx:  0.999954641\n",
      "d^2y/dx^2 4.53546054e-05\n"
     ]
    }
   ],
   "source": [
    "################################\n",
    "# CODE START                   #\n",
    "################################\n",
    "\n",
    "# pass\n",
    "\n",
    "#references: https://docs.w3cub.com/tensorflow~1.15/gradienttape\n",
    "#            https://www.tensorflow.org/api_docs/python/tf/custom_gradient\n",
    "    \n",
    "x = tf.constant(10.0)\n",
    "with tf.GradientTape(persistent=True) as g:\n",
    "  g.watch(x)\n",
    "  with tf.GradientTape(persistent=True) as gg:\n",
    "    gg.watch(x)\n",
    "    y = tf.math.log(1 + tf.exp(x))\n",
    "  dy_dx = gg.gradient(y, x)\n",
    "d2y_dx2 = g.gradient(dy_dx, x)\n",
    "\n",
    "sess.run(tf.print(\"dy/dx: \", dy_dx))\n",
    "sess.run(tf.print(\"d^2y/dx^2\", d2y_dx2)) #printed in floating point arithmetic\n",
    "\n",
    "################################\n",
    "# CODE END                     #\n",
    "################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Assignment 2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
