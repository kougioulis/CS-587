{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4aTsGY52uwNs"
   },
   "source": [
    "# CS - 587:  Exercise 4b\n",
    "\n",
    "We will you a pretrained model, in our case a VGG_16 to compute class saliency maps as described in Section 3.1 of [2].\n",
    "\n",
    "A saliency map tells us the degree to which each pixel in the image affects the classification score for that image. To compute it, we compute the gradient of the unnormalized score corresponding to the correct class (which is a scalar) with respect to the pixels of the image. If the image has shape (H, W, 3) then this gradient will also have shape (H, W, 3); for each pixel in the image, this gradient tells us the amount by which the classification score will change if the pixel changes by a small amount. To compute the saliency map, we take the absolute value of this gradient, then take the maximum value over the 3 input channels; the final saliency map thus has shape (H, W) and all entries are nonnegative.\n",
    "\n",
    "[2] Karen Simonyan, Andrea Vedaldi, and Andrew Zisserman. \"Deep Inside Convolutional Networks: Visualising Image Classification Models and Saliency Maps\", ICLR Workshop 2014."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VDmdzOhvuwNz"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from models import vgg16\n",
    "from Utilities import utils\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import pylab as P\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Lay7kBAtuwNz"
   },
   "outputs": [],
   "source": [
    "#Load the image to be processed\n",
    "img = utils.load_image(\"flamingo1.jpg\")\n",
    "\n",
    "# Plot the image of this magestic creature\n",
    "imgplot = plt.imshow(img)\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "t5sf3R7wuwN0"
   },
   "outputs": [],
   "source": [
    "# Add some useful functions that will ease the visualization process\n",
    "def VisualizeImageGrayscale(image_3d, percentile=99):\n",
    "  #Returns a 3D tensor as a grayscale 2D tensor.\n",
    "\n",
    "  #This method sums a 3D tensor across the absolute value of axis=2, and then\n",
    "  #clips values at a given percentile.\n",
    " \n",
    "  image_2d = np.sum(np.abs(image_3d), axis=2)\n",
    "\n",
    "  vmax = np.percentile(image_2d, percentile)\n",
    "  vmin = np.min(image_2d)\n",
    "\n",
    "  return np.clip((image_2d - vmin) / (vmax - vmin), 0, 1)\n",
    "\n",
    "def VisualizeImageDiverging(image_3d, percentile=99):\n",
    "  #Returns a 3D tensor as a 2D tensor with positive and negative values.\n",
    "  image_2d = np.sum(image_3d, axis=2)\n",
    "\n",
    "  span = abs(np.percentile(image_2d, percentile))\n",
    "  vmin = -span\n",
    "  vmax = span\n",
    "\n",
    "  return np.clip((image_2d - vmin) / (vmax - vmin), -1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dPr2PRcguwN1"
   },
   "source": [
    "## Class Saliency Map\n",
    "\n",
    "In order to compute the saliency map of a specific class the following steps are required:\n",
    "Following are the steps involved:\n",
    "\n",
    "1. Do a forward pass of the image through the network.\n",
    "2. Calculate the scores for every class.\n",
    "3. Enforce derivative of score S at last layer for all classes except class C to be 0. For C, set it to 1.\n",
    "4. Backpropagate this derivative till the start.\n",
    "5. Render the gradients and you have your Saliency Map!\n",
    "\n",
    "More information about the role of each step can be found in:\n",
    "https://www.silversparro.com/single-post/2018/01/26/Understanding-Deep-Learning-Networks-using-Saliency-Maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "DCyq2RtDuwN1"
   },
   "outputs": [],
   "source": [
    "##############################------PART  4 -------------##################################################################\n",
    "#                                                                                                                         # \n",
    "# We will start with steps 3 and 4: we will define a class that enforces the derivative of an input (Score class)         # \n",
    "# to be 1 and backpropagates this derivative till the start.                                                              #\n",
    "#                                                                                                                         #\n",
    "###########################################################################################################################\n",
    "\n",
    "class Saliency(object):\n",
    "  #Base class for saliency masks. Alone, this class doesn't do anything.#\n",
    "  def __init__(self, graph, session, y, x):\n",
    "    #Constructs a SaliencyMask by computing dy/dx.\n",
    "\n",
    "    #Args:\n",
    "    #  graph: The TensorFlow graph to evaluate masks on.\n",
    "    #  session: The current TensorFlow session.\n",
    "    #  y: The output tensor to compute the SaliencyMask against. This tensor\n",
    "    #      should be of size 1.\n",
    "    #  x: The input tensor to compute the SaliencyMask against. The outer\n",
    "    #      dimension should be the batch size.\n",
    "    \n",
    "    # y must be of size one, otherwise the gradient we get from tf.gradients\n",
    "    # will be summed over all ys.\n",
    "    \n",
    "    size = 1\n",
    "    for shape in y.shape:\n",
    "      size *= shape\n",
    "    assert size == 1\n",
    "\n",
    "    self.graph = graph\n",
    "    self.session = session\n",
    "    self.y = y\n",
    "    self.x = x\n",
    "\n",
    "  def Mask_GEN(self, x_value, feed_dict={}):\n",
    "    #Returns an unsmoothed mask.\n",
    "\n",
    "    #Args:\n",
    "    #  x_value: Input value, not batched.\n",
    "    #  feed_dict: (Optional) feed dictionary to pass to the session.run call.\n",
    "    \n",
    "    raise NotImplementedError('A derived class should implemented GetMask()')\n",
    "    \n",
    "###################################################################################\n",
    "# TODO: Implement the Gradient saliecy class so as to do the following:           #\n",
    "#              a) Returns the backward pass (gradient ascent) of the activation   #\n",
    "#                  w.r.t to the input image                                       # \n",
    "#                                                                                 #\n",
    "###################################################################################    \n",
    "\n",
    "class Get_Gradient(Saliency):\n",
    "  #A SaliencyMask class that computes saliency masks with a gradient.\n",
    "\n",
    "  def __init__(self, graph, session, y, x):\n",
    "        \n",
    "        ############################################################\n",
    "        #       Start of your code #HINT: take a look at tf.gradients\n",
    "        # Backward pass gradient must be stored in the gradients_node variable           \n",
    "        pass\n",
    "        #       End of your code\n",
    "        ############################################################\n",
    "        \n",
    "  def Mask_GEN(self, x_value, feed_dict={}):\n",
    "    #Returns a vanilla gradient mask.\n",
    "\n",
    "    #Args:\n",
    "    #  x_value: Input value, not batched.\n",
    "    #  feed_dict: (Optional) feed dictionary to pass to the session.run call.\n",
    "    \n",
    "    feed_dict[self.x] = [x_value]\n",
    "    return self.session.run(self.gradients_node, feed_dict=feed_dict)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iSEEgDe9uwN3",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "resize_image = img.reshape(1, 224, 224, 3) #----LOOK AT ME! I am the current CAPTAIN image now!!!-----#############\n",
    "#SO FEED ME INTO THE VGG's stomach!------------------------------------------------------\n",
    "\n",
    "graph = tf.Graph()\n",
    "\n",
    "with graph.as_default():\n",
    "  sess = tf.Session(graph=graph)\n",
    "\n",
    "   ######################################################################################\n",
    "  # TODO: Implement entire Saliency computation pipeline by:                           #\n",
    "  #              a) Computing steps 1 and 2                                            #\n",
    "  #           TODO a.1) Do a forward pass of the image through the network.            #\n",
    "  #           TODO a.2) Calculate the scores for every class.                          #\n",
    "  #             b) Moving to steps 3 and 4                                             # \n",
    "  #           TODO  b.1) Take the logit for the specific class (the one that gives     #\n",
    "  #                       the highest prediction)  -- should output 130 - make a print #\n",
    "  #           TODO  b.2) Call Get_Gradient() to compute gradients                      #\n",
    "  #           TODO  b.3) Call Get_Gradient.Mask_GEN for the SPECIFIC GRADIENTS to      #\n",
    "  #                       compute the Mask of activations                              #\n",
    "  #           TODO  b.4) Call VisualizeImageGrayscale to visualize the Saliency Map    #\n",
    "  #                                                                                    #\n",
    "  ######################################################################################    \n",
    "    \n",
    "  # START of code for Task a -  HINT: call vgg16.VGG16.build (INPUT TENSOR) to first build the model (load weights, etc.), \n",
    "  # to take the output of your model just call model.prob, where model is the VGG model that you have created.\n",
    "  \n",
    "  # Steps 1-2 of a, name the oupts of the model as logits\n",
    "  \n",
    "  # START\n",
    "\n",
    "  # ENTER YOUR CODE HERE    \n",
    "\n",
    "\n",
    "  # END \n",
    "\n",
    "  neuron_selector = tf.placeholder(tf.int32) \n",
    "  y = logits[0][neuron_selector]\n",
    "  \n",
    "\n",
    "  # TODO Step 1 of b\n",
    "  # Define the operation that finds the class that gives me the highest score, use tf.argmax\n",
    "  # RUN the operation, via session.run and input the placeholder of the image. Print the result! Should be 130.\n",
    " \n",
    "\n",
    "  # TODO Step 2 of b\n",
    "  # Use as input on the function, the graph, the current session and the placeholder of the input image.\n",
    "  pass\n",
    "\n",
    "\n",
    "\n",
    "  # END of code... up to task b.2\n",
    "  # Step 3 of b --- PARTIALLY IMPLEMENTED, just fill what I ask you in CAPS\n",
    " \n",
    "  # Compute the vanilla mask.\n",
    "  mask_3d = gradient_CS587.Mask_GEN(img, feed_dict = {neuron_selector: YOUR OPERATION TO GET THE PREDICTED})\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4sMjceDBuwN4"
   },
   "outputs": [],
   "source": [
    "##############################################################################  \n",
    "# ENTER THE CODE HERE FOR task b.4\n",
    "#############################################################################\n",
    "# Call the visualization methods to convert the 3D tensors to 2D grayscale.\n",
    "# INPUT will be the mask_3d that you generated in step 3.b\n",
    "# TO do the visuallization in grayscale call the function VisualizeImageGrayscale\n",
    "# The method returns an image. TO SHOW IT use imshow function of matplotlib.\n",
    "\n",
    "pass\n",
    "\n",
    "#END of code for task b.4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "MLwumHOkuwN4"
   },
   "outputs": [],
   "source": [
    "  ######################################################################################\n",
    "  # TODO: Repeat the process for the rest of images, located in folder = MyImages      #\n",
    "  #              a) Load them and create the tensor to hold them (i.e. correct shape)  #\n",
    "  #              b) Repeat the steps in previous task for ALL new images               #\n",
    "  #              c) Show predicted class for each image and plot Saliency Map          #\n",
    "  #                                                                                    #\n",
    "  # ####################################################################################           \n",
    "\n",
    "pass\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Assignment_3b.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
